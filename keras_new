import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras import Model
import keras.backend as K
from keras.layers import Embedding, Reshape, Input, Dot,Dense,concatenate,Conv2D,MaxPool2D,Flatten,Lambda,Dropout
from keras.models import Sequential
from keras.layers.core import Lambda



# 读入数据
from sklearn.utils import shuffle

u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv('C:/Users/L/Desktop/数据集/电影评分/ml-100k/ml-100k/u.user', sep='|', names=u_cols,encoding='latin-1')

r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']
ratings = pd.read_csv('C:/Users/L/Desktop/数据集/电影评分/ml-100k/ml-100k/u.data', sep='\t', names=r_cols,encoding='latin-1')

m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']
movies = pd.read_csv('C:/Users/L/Desktop/数据集/电影评分/ml-100k/ml-100k/u.item', sep='|', names=m_cols, usecols=range(5),encoding='latin-1')


gender_map = {'F': 0, 'M': 1}
users['sex'] = users['sex'].map(gender_map)
# print(users['sex'])

print(users['age'])
print("-----------------------------------")
# print(users['age'][0])


# print(users['age'].shape[0])

x = np.zeros(users['age'].shape[0])

for i in range(0, 943):
    if 0 < users['age'][i] < 15:
        x[i] = 0

    if 15 < users['age'][i] < 25:
        x[i] = 1

    if 25 < users['age'][i] < 35:
        x[i] = 2

    if 35 < users['age'][i] < 45:
        x[i] = 3

    if 45 < users['age'][i] < 55:
        x[i] = 4

    if users['age'][i] > 55:
        x[i] = 5

users.insert(3, 'ages', x)
users['ages'] = users['ages'].astype(np.int64)

# print(users['ages'])

job_map = {'administrator': 0, 'artist': 1,'doctor': 2,'educator': 3,'engineer': 4,'entertainment': 5,'executive': 6,'healthcare': 7,'homemaker': 8,'lawyer': 9,'librarian': 10,'marketing': 11,'none': 12,'other': 13,'programmer': 14,'retired': 15,'salesman': 16,'scientist': 17,'student': 18,'technician': 19,'writer': 20}
users['occupation'] = users['occupation'].map(job_map)

# print("---------------------职业-------------------------")
# print(users['occupation'])

# 电影Title转数字字典
title_set = set()
for val in movies['title'].str.split():
    title_set.update(val)

# print(title_set)

title_set.add('<PAD>')
title2int = {val: ii for ii, val in enumerate(title_set)}

# print(title2int)

# 将电影Title转成等长数字列表，长度是20
title_count = 20
title_map = {val:[title2int[row] for row in val.split()] for ii,val in enumerate(set(movies['title']))}

#
for key in title_map:
    for cnt in range(title_count - len(title_map[key])):
        title_map[key].insert(len(title_map[key]) + cnt,title2int['<PAD>'])

movies['title'] = movies['title'].map(title_map)

# print("---------------------电影名-------------------------")
# print(movies['title'])
#
#
user_df = users[['user_id', 'ages', 'sex', 'occupation']]
print("---------------------user_df-------------------------")
print(user_df)

user = user_df.values

user_df.to_csv("C:/Users/L/Desktop/dataset/user_df.csv")

movies_df = movies[['movie_id', 'title']]
print("---------------------movies_df-------------------------")
print(movies_df)
movies = movies_df.values

movies_df.to_csv("C:/Users/L/Desktop/dataset/movies_df.csv")


ratings_df = ratings[['user_id', 'movie_id', 'rating']]
print("---------------------ratings_df-------------------------")
print(ratings_df)
ratings = ratings_df.values

ratings_df.to_csv("C:/Users/L/Desktop/dataset/ratings_df.csv")


data = pd.merge(pd.merge(ratings_df, user_df), movies_df)

# data.to_csv("C:/Users/L/Desktop/data.csv")



# 将数据分成X和y两张表
print("---------------------分表:输入、输出-------------------------")
target_fields = ['rating']
features_pd, targets_pd = data.drop(target_fields, axis=1), data[target_fields]

findex = features_pd.index
features = features_pd.values
targets_values = targets_pd.values

# print("---------------------取列数据-------------------------")
# print(max(features.take(0,1)))
# print(max(features.take(1,1)) + 1)
# print(max(features.take(2,1)) + 1)
# print(max(features.take(3,1)) + 1)
# print(max(features.take(4,1)) + 1)

# 嵌入矩阵的维度
print("---------------------准备初始数据-------------------------")
embed_dim = 32
# 用户ID个数  610 + 1 = 611
uid_max = max(features.take(0,1)) + 1
# 年龄类别个数    5 + 1 = 6
age_max = max(features.take(2,1)) + 1
# 性别个数  1 + 1 = 2
gender_max = max(features.take(3,1)) + 1
# 职业个数  20 + 1 = 21
job_max = max(features.take(4,1)) + 1

# 电影ID个数   1682 + 1 = 1683
# movie_num = movieid2idx[max(features.take(1,1))]+1
movie_id_max = max(features.take(1,1)) + 1

# 电影名单词个数
movie_title_max = len(title_set)

# 行数    10000 + 1 = 10001
row_max = max(findex)+1

# print(uid_max)
# print(age_max)
# print(gender_max)
# print(job_max)
# print(movie_id_max)
# print(movie_title_max)
# print(row_max)

# 打乱一下顺序
# data = shuffle(data)

# 电影名长度 20
sentences_size = title_count
# 文本卷积滑动窗口，分别滑动2, 3, 4, 5个单词
window_sizes = [2, 3, 4, 5]
# 文本卷积核数量
filter_num = 8

# 定义超参
num_epochs = 1
# Batch Size
batch_size = 256

dropout_keep = 0.5
# Learning Rate
learning_rate = 0.0001
# Show stats for every n number of batches
show_every_n_batches = 20

# 划分训练集和测试集
train_x, test_x, train_y, test_y = train_test_split(features,targets_values,test_size=0.3,random_state=0)

print("数据划分完毕...")

len1 = len(train_x)
len2 = len(test_x)

# 处理训练集的 categories 和 title

uid1 = train_x.take(0, 1)
user_gender1 = train_x.take(3, 1)
user_age1 = train_x.take(2, 1)
user_job1 = train_x.take(4, 1)
movie_id1 = train_x.take(1, 1)


titles = np.zeros([len1, 20])  # sentences_size
for i in range(len1):
    titles[i] = train_x.take(5, 1)[i]

movie_titles1 = titles

print("训练集 --> movie_titles处理完成")


# 处理测试集的 categories 和 title

uid2 = test_x.take(0, 1)
user_gender2 = test_x.take(3, 1)
user_age2 = test_x.take(2, 1)
user_job2 = test_x.take(4, 1)
movie_id2 = test_x.take(1, 1)


titles = np.zeros([len2, 20])  # sentences_size
for i in range(len2):
    titles[i] = test_x.take(5, 1)[i]

movie_titles2 = titles

print("测试集 --> movie_titles处理完成")


# print(user[0])
# print(user[0][0])


K.clear_session()

# 构建一个顺序模型

# 获取用户特征，将各特征做简单的拼接即可
def get_user_feature_layer(input_uid,input_age,input_gender,input_job):

    # uid
    print(input_uid)
    embedding1 = Embedding(uid_max,embed_dim , input_length=1)(input_uid)       # (?, ?, 32)

    print(embedding1)
    embedding1 = Reshape((1,embed_dim))(embedding1)        # (?, 1, 32)
    print(embedding1)
    # print(embedding1.shape)

    # user_age
    embedding2 =Embedding(age_max,32 ,input_length=1)(input_age)
    embedding2 = Reshape((1, embed_dim))(embedding2)

    # user_gender
    embedding3 = Embedding(gender_max,32, input_length=1)(input_gender)
    embedding3 = Reshape((1, embed_dim))(embedding3)

    # user_job
    embedding4 = Embedding(job_max,32, input_length=1)(input_job)
    embedding4 = Reshape((1, embed_dim))(embedding4)

    x = concatenate([embedding1, embedding2,embedding3,embedding4],axis=2)

    print(x)
    user_combine_layer = Dense(140, activation='relu')(x)       #200
    #
    # dropout = Dropout(dropout_keep)(user_combine_layer)
    #
    user_combine_layer = Reshape((140,))(user_combine_layer)

    # 这里的报错为：NOT CONVERTIBLE TO TENSOR，应该是输入有误
    model = Model(inputs=[input_uid, input_age,input_gender,input_job], outputs=user_combine_layer)

    model.compile(loss='mse',optimizer='adam')
    print(user_combine_layer.shape)                 # (?, 1, 200)
    # print(model.summary())

    return model

# result = get_user_feature_layer()

print("******************************************************************************")


def get_movie_feature_layer(input_movie_id,input_movie_title):
    # uid
    embedding1 = Embedding(movie_id_max,embed_dim , input_length=1)(input_movie_id)
    print(embedding1)
    embedding1 = Reshape((1,embed_dim))(embedding1)         # (?, 1, 32)
    print(embedding1)


    # movie_title
    embedding3 = Embedding(movie_title_max, embed_dim, input_length=20)(input_movie_title)
    # print(embedding3)
    embedding3 = Reshape((20, embed_dim, 1))(embedding3)
    # embedding3 = Lambda(lambda embedding3: K.sum(embedding3, axis=1, keepdims=True))(embedding3)

    print(embedding3)
    # cnn
    x = Conv2D(filters=32, kernel_size=(window_sizes[0], embed_dim), padding='valid', activation='relu')(embedding3)
    y = Conv2D(filters=32, kernel_size=(window_sizes[1], embed_dim), padding='valid', activation='relu')(embedding3)
    z = Conv2D(filters=32, kernel_size=(window_sizes[2], embed_dim), padding='valid', activation='relu')(embedding3)

    print(x)
    print(y)
    print(z)

    maxpool_0 = MaxPool2D(pool_size=(sentences_size - window_sizes[0] + 1, 1), strides=(1, 1), padding='valid')(x)
    maxpool_1 = MaxPool2D(pool_size=(sentences_size - window_sizes[1] + 1, 1), strides=(1, 1), padding='valid')(y)
    maxpool_2 = MaxPool2D(pool_size=(sentences_size - window_sizes[2] + 1, 1), strides=(1, 1), padding='valid')(z)

    print(maxpool_0)
    print(maxpool_1)
    print(maxpool_2)

    concatenated_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)
    flatten = Flatten()(concatenated_tensor)
    # dropout = Dropout(dropout_keep)(flatten)
    # print(dropout)
    movie_combine_layer = Dense(32, activation='relu')(flatten)  # (?,32)

    embedding3 = Reshape((1, embed_dim))(movie_combine_layer)       # (?,1,32)


    print("************** test ***************")
    print(embedding3)

    # 连接
    concat = concatenate([embedding1, embedding3], axis=2)

    # my_concat = Lambda(K.concatenate([embedding1, embedding2], axis=2))
    # x = my_concat([embedding1, embedding2])

    print("concat")
    print(concat)

    movie_combine_layer = Dense(140, activation='relu')(concat)
    #
    # dropout = Dropout(dropout_keep)(movie_combine_layer)
    #
    movie_combine_layer = Reshape((140,))(movie_combine_layer)

    # 这里的报错为：NOT CONVERTIBLE TO TENSOR，应该是输入有误
    model = Model(inputs=[input_movie_id, input_movie_title], outputs=movie_combine_layer)

    model.compile(loss='mse',optimizer='adam')
    # print(model.summary())
    print("movie_combine_layer")
    print(movie_combine_layer.shape)

    return model


# result = get_movie_feature_layer()



def merge_model():

    input_uid = Input(shape=[None, ], dtype="int32")
    input_age = Input(shape=[None, ], dtype="int32")
    input_gender = Input(shape=[None, ], dtype="int32")
    input_job = Input(shape=[None, ], dtype="int32")
    input_movie_id = Input(shape=[None, ], dtype="int32")
    # input_movie_categories = Input(shape=[None, ], dtype="int32")
    input_movie_title = Input(shape=[None, ], dtype="int32")

    model_1 = get_user_feature_layer(input_uid,input_age,input_gender,input_job)
    print("model1执行完毕")
    # model_3 = get_movie_title_layer(input_movie_title)
    # print("model3执行完毕")
    # # 卷积后的特征向量作为model_2的输入
    # title_layer = model_3.output

    # 注意,如果报错，可能是这里的问题
    # embedding3 = Reshape((1, embed_dim))(title_layer)
    model_2 = get_movie_feature_layer(input_movie_id, input_movie_title)

    print("model2执行完毕")
    users_matrics = model_1.output
    movie_matrics = model_2.output

    print("现在开始做用户和电影的向量内积....")
    # temp = K.transpose(movie_matrics)
    # print(temp)
    out = Dot(1)([users_matrics, movie_matrics])
    print("out")
    print(out)
    # score = Lambda(lambda embedding3,temp:tf.matmul(users_matrics,temp))(users_matrics,temp)
    # print(score)
    print("before")
    model = Model(inputs=[input_uid, input_age, input_gender, input_job, input_movie_id, input_movie_title], outputs=out)
    print("after")
    model.compile(loss='mse', optimizer='Adam',metrics=['accuracy'])

    return model

# last_model = merge_model()
print("训练结束")

model = merge_model()
model.fit([uid1, user_age1, user_gender1, user_job1, movie_id1, movie_titles1], train_y, batch_size=128, epochs=5)
print("保存中...")
model.save("D:\Anaconda\Pycharm\content\myrepo\my_mdoel4.h5")
print("程序结束")

loss, acc = model.evaluate([uid2, user_age2, user_gender2, user_job2, movie_id2, movie_titles2], test_y)

print("损失值：")
print(loss)
print("准确率：")
print(acc)


print("预测值：")

result = np.array([])
for i in range(0,50):
    temp = model.predict([np.array([user[21][0]]), np.array([user[21][1]]), np.array([user[21][2]]), np.array([user[21][3]]),np.array([movies[i][0]]), np.array([movies[i][1]])])
    print(temp)
    result = np.append(result,temp)

print("save")
print(result)
print(type(result))
